{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시계열 데이터에서 멀리 떨어진, 장기(long term) 의존 관계를 잘 학습할 수 없음\n",
    "    - BPTT에서 기울기 소실/폭발이 일어나기 때문\n",
    "<br/> <img src='../figs/fig%206-3.png'> <br/>\n",
    "- '?'에 들어가는 단어는 'Tom'  \n",
    "RNNLM이 위 질문에 답하기 위해서는 'Tom이 방에서 TV를 보고 있음'과 'Mary가 방에 들어옴'이라는 두 정보를 모두 기억해야 함.  \n",
    "<br/> <img src='../figs/fig%206-4.png'> <br/>\n",
    "위 그림에서 빨간색 화살표를 따라 기울기를 전달하여 학습하는데, 단어간의 거리가 멀어지면(long-term) 결국 기울기가 작아지거나(소실), 커져서(폭발) 장기 의존 관계를 학습할 수 없게 됨.  \n",
    "<br/>\n",
    "- 기울기 소실(vanishing gradient)이 일어나는 이유\n",
    "    - $y = tanh(x)$의 미분은 ${\\partial y \\over \\partial x} = 1 - y^2$으로 역전파 과정에서 기울기가 tanh 노드를 지날때마다 작아짐\n",
    "- 기울기 폭발(exploding gradients)\n",
    "    - Matrix multiplication을 실행하면서 시간에 따라 \n",
    "    - Wh의 singular value의 최댓값이 1보다 큰 경우 : 기울기가 exponentially 증가\n",
    "    - 1보다 작은 경우: 기울기가 exponentially 감소(이 경우 vanishing gradient)  \n",
    "[30] 'On the difficulty of training recurrent neural networks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:00:33.355622Z",
     "start_time": "2021-10-24T04:00:33.019668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2970dead908>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['D2Coding ligature'] not found. Falling back to DejaVu Sans.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 2\n",
    "H = 3\n",
    "T = 20\n",
    "\n",
    "# Vanishing gradients\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3)\n",
    "Wh = np.random.randn(H, H) * 0.5\n",
    "\n",
    "norm_list = []\n",
    "\n",
    "for t in range(T):\n",
    "    dh = np.matmul(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)\n",
    "\n",
    "plt.plot(norm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:00:37.387984Z",
     "start_time": "2021-10-24T04:00:36.967622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2970e573fc8>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploding gradients\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3)\n",
    "Wh = np.random.randn(H, H)\n",
    "\n",
    "norm_list = []\n",
    "\n",
    "for t in range(T):\n",
    "    dh = np.matmul(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)\n",
    "\n",
    "plt.plot(norm_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기울기 폭발의 해결방법 중 하나.  \n",
    "$if~~\\| \\hat g \\| \\geq theshold~:~~~ \\hat g = {threshold \\over \\| \\hat g \\|} \\hat g $  \n",
    "- 기울기 g가 일정 값(threshold) 이상으로 커지면 기울기를 수정해 주는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:00:38.424379Z",
     "start_time": "2021-10-24T04:00:38.400349Z"
    }
   },
   "outputs": [],
   "source": [
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    # g hat 계산\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad**2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:00:38.925411Z",
     "start_time": "2021-10-24T04:00:38.910259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[6.49144048, 2.78487283, 6.76254902],\n",
      "       [5.90862817, 0.23981882, 5.58854088],\n",
      "       [2.59252447, 4.15101197, 2.83525082]]), array([[6.93137918, 4.40453718, 1.56867738],\n",
      "       [5.44649018, 7.80314765, 3.06363532],\n",
      "       [2.21957884, 3.87971258, 9.3638365 ]])]\n",
      "[array([[1.49503731, 0.64138134, 1.55747605],\n",
      "       [1.36081038, 0.05523244, 1.28709139],\n",
      "       [0.59708178, 0.95601551, 0.65298384]]), array([[1.59635916, 1.01440465, 0.36128056],\n",
      "       [1.25437583, 1.79713531, 0.70558286],\n",
      "       [0.51118903, 0.89353281, 2.15657603]])]\n"
     ]
    }
   ],
   "source": [
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "print(grads)\n",
    "clip_grads(grads, max_norm)\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 vanishing gradient를 해결하기 위해서 '게이트가 추가된 RNN'을 도입할 것  \n",
    "대표적으로 LSTM, GRU가 있고, LSTM을 먼저 다룰 것임  \n",
    "<br/> <img src='../figs/fig%206-15.png' width='300px'> <br/>\n",
    "- LSTM에는 기존 RNN과 다르게 기억 셀(memory cell) $c$라는 경로가 있음  \n",
    "    - $c_t$에는 시각 $t$에서의 LSTM의 기억이 저장되어 있음  \n",
    "    이 $c_t$를 통해 $h_t=tanh(c_t)$를 계산  \n",
    "    \n",
    "#### output gate의 열림 상태\n",
    "$o = \\sigma(x_{t} W_{x}^{(o)} + h_{t-1}W_{h}^{(o)} + b^{(o)})$\n",
    "    - $tanh(c_t)$의 원소들에 대해 '그것이 다음 시각의 hidden state에 얼마나 중요한가'를 조정  \n",
    "    - 여기서 $\\sigma$(sigmoid)의 출력은 0~1로 데이터를 얼마만큼 통과시킬지를 정하는 비율  \n",
    "    \n",
    "#### output gate    \n",
    "$h_{t} = o \\circ tanh(c_{t})$\n",
    "    - 여기서 tanh의 출력은 -1.0~1.0으로 '정보'의 강약(정도)를 표시한다고 볼 수 있음  \n",
    "    - 정보를 얼마만큼 통과시킬지 정하는 sigmoid와 다르게 실질적인 '정보'를 지니는 데이터에는 tanh를 주로 사용\n",
    "    \n",
    "#### forget gate\n",
    "<img src='../figs/fig%206-16.png' width='300px'> <br/>\n",
    "- $c_{t-1}$의 기억 중 불필요한 기억을 잊게 해주는 게이트  \n",
    "    - $f = \\sigma(x_{t} W_{x}^{(f)} + h_{t-1}W_{h}^{(f)} + b^{(f)})$   \n",
    "    - $c_{t} = f \\circ c_{t-1}$\n",
    "\n",
    "#### 새로운 기억 셀\n",
    "<img src='../figs/fig%206-17.png' width='300px'> <br/>\n",
    "- 새로 기억해야 할 정보를 기억 셀 $c$에 추가    \n",
    "    - $g = \\tanh(x_{t} W_{x}^{(g)} + h_{t-1}W_{h}^{(g)} + b^{(g)})$   \n",
    "    - 잊어버릴 정보가 아니라 실질적으로 '기억'해야할 정보기 때문에 $sigmoid$가 아닌 $tanh$ 사용\n",
    "    \n",
    "#### input gate\n",
    "<img src='../figs/fig%206-18.png' width='300px'> <br/>   \n",
    "- 위의 $g$로 새로 추가되는 정보가 얼마나 가치있는 정보인지 판단하기 위해 input gate로 가중치를 줌\n",
    "    - $i = \\sigma(x_{t} W_{x}^{(i)} + h_{t-1}W_{h}^{(i)} + b^{(i)})$   \n",
    "    - 이후 $i$와 $g$의 원소별 곱을 기억 셀 $c$에 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM의 기울기 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기억 셀 c의 역전파 흐름을 보면 $+$와 $\\times$ 노드를 지남  \n",
    "- $+$ 노드를 지날때는 기울기 변화가 일어나지 않음\n",
    "- $\\times$ 노드의 경우 matrix multiplication이 아닌 hadamard product(elementwise)를 계산하기 때문에 기울기 소실이 일어나기 어려움\n",
    "- 특히 $\\times$ 연산을 제어하는 forget gate가 잊어야할 정보와 잊어서는 안될 정보를 판단해주기 때문에 '오래 기억해야 할 정보'의 경우 기울기가 소실 없이 전파될 것을 기대할 수 있음\n",
    "\n",
    "<br/> <img src='../figs/fig%206-19.png'> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 네가지 게이트에서 일어나는 계산들은 $W$만 다를 뿐 같은 계산을 수행함.(Affine transformation)\n",
    "- 4개의 가중치 $W$를 하나로 모아서 한번의 affine transformation만 수행할것임.\n",
    "<br/> <img src='../figs/e%206-6.png'> <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:06:47.801630Z",
     "start_time": "2021-10-24T04:06:47.765903Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.matmul(x, Wx) + np.matmul(h_prev, Wh) + b\n",
    "        \n",
    "        # slice\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "    \n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "        \n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "        # ?\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next **2)\n",
    "        \n",
    "        dc_prev = ds * f\n",
    "        df = ds * c_prev\n",
    "        dg = ds * i\n",
    "        di = ds * g\n",
    "        do = dh_next * tanh_c_next\n",
    "        \n",
    "        df *= f * (1 - f)\n",
    "        dg *= (1 - g**2)\n",
    "        di *= i * (1 - i)\n",
    "        do *= o * (1 - o)\n",
    "        \n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "        \n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "        \n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- T개의 시계열 데이터를 한꺼번에 처리하는 T개의 LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:06:48.673570Z",
     "start_time": "2021-10-24T04:06:48.639617Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype = 'f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype = 'f')\n",
    "            \n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype = 'f')\n",
    "            \n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "            \n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype = 'f')\n",
    "        dh, dc = 0, 0\n",
    "        grads = [0, 0, 0]\n",
    "        \n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "            \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        \n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "    \n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM을 사용한 RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:06:49.651937Z",
     "start_time": "2021-10-24T04:06:49.617579Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "import pickle\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:04:19.931976Z",
     "start_time": "2021-10-24T04:04:19.905926Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from data import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:04:47.242857Z",
     "start_time": "2021-10-24T04:04:47.229437Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:05:43.629750Z",
     "start_time": "2021-10-24T04:05:41.548213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# load dataa\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T04:06:52.696652Z",
     "start_time": "2021-10-24T04:06:52.497769Z"
    }
   },
   "outputs": [],
   "source": [
    "# model 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:10:25.964851Z",
     "start_time": "2021-10-24T04:07:28.349987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| current_epoch 1 |  iters 1 / 1327 | time 1.0497894287109375[s] | perplexity 9999.937519272651\n",
      "| current_epoch 1 |  iters 21 / 1327 | time 16.190855026245117[s] | perplexity 2821.480384443953\n",
      "| current_epoch 1 |  iters 41 / 1327 | time 31.35884690284729[s] | perplexity 1261.3791155142342\n",
      "| current_epoch 1 |  iters 61 / 1327 | time 46.12487435340881[s] | perplexity 968.5359917598987\n",
      "| current_epoch 1 |  iters 81 / 1327 | time 61.4105429649353[s] | perplexity 809.3184328795666\n",
      "| current_epoch 1 |  iters 101 / 1327 | time 76.20887470245361[s] | perplexity 657.2590707034198\n",
      "| current_epoch 1 |  iters 121 / 1327 | time 90.92674732208252[s] | perplexity 640.8644772385672\n",
      "| current_epoch 1 |  iters 141 / 1327 | time 105.86041116714478[s] | perplexity 593.6969690010263\n",
      "| current_epoch 1 |  iters 161 / 1327 | time 120.71081781387329[s] | perplexity 588.6734507433605\n",
      "| current_epoch 1 |  iters 181 / 1327 | time 135.8206696510315[s] | perplexity 595.1390829806868\n",
      "| current_epoch 1 |  iters 201 / 1327 | time 150.58978486061096[s] | perplexity 502.0079027838763\n",
      "| current_epoch 1 |  iters 221 / 1327 | time 165.65865421295166[s] | perplexity 494.2603981158055\n",
      "| current_epoch 1 |  iters 241 / 1327 | time 180.4621639251709[s] | perplexity 436.10677161749163\n",
      "| current_epoch 1 |  iters 261 / 1327 | time 195.38004851341248[s] | perplexity 468.1185496491003\n",
      "| current_epoch 1 |  iters 281 / 1327 | time 210.47923874855042[s] | perplexity 453.73408821155516\n",
      "| current_epoch 1 |  iters 301 / 1327 | time 225.44069504737854[s] | perplexity 382.69726478591724\n",
      "| current_epoch 1 |  iters 321 / 1327 | time 240.63085412979126[s] | perplexity 338.03743157280286\n",
      "| current_epoch 1 |  iters 341 / 1327 | time 255.30699229240417[s] | perplexity 402.8831156921893\n",
      "| current_epoch 1 |  iters 361 / 1327 | time 270.0117485523224[s] | perplexity 403.4071818148299\n",
      "| current_epoch 1 |  iters 381 / 1327 | time 284.9545841217041[s] | perplexity 338.43880616843563\n",
      "| current_epoch 1 |  iters 401 / 1327 | time 299.8407669067383[s] | perplexity 354.16947097066287\n",
      "| current_epoch 1 |  iters 421 / 1327 | time 315.79708671569824[s] | perplexity 348.906418989364\n",
      "| current_epoch 1 |  iters 441 / 1327 | time 330.7690432071686[s] | perplexity 332.18094217611815\n",
      "| current_epoch 1 |  iters 461 / 1327 | time 345.3498549461365[s] | perplexity 328.5066828411822\n",
      "| current_epoch 1 |  iters 481 / 1327 | time 359.77477860450745[s] | perplexity 310.10242316189857\n",
      "| current_epoch 1 |  iters 501 / 1327 | time 374.02951169013977[s] | perplexity 313.8160345800158\n",
      "| current_epoch 1 |  iters 521 / 1327 | time 388.31604623794556[s] | perplexity 302.5843630970203\n",
      "| current_epoch 1 |  iters 541 / 1327 | time 403.1833550930023[s] | perplexity 317.3857196058638\n",
      "| current_epoch 1 |  iters 561 / 1327 | time 417.51706194877625[s] | perplexity 289.1407393029645\n",
      "| current_epoch 1 |  iters 581 / 1327 | time 431.84992957115173[s] | perplexity 259.3876092467567\n",
      "| current_epoch 1 |  iters 601 / 1327 | time 445.98690724372864[s] | perplexity 338.95905125902146\n",
      "| current_epoch 1 |  iters 621 / 1327 | time 460.50423669815063[s] | perplexity 310.5195116894611\n",
      "| current_epoch 1 |  iters 641 / 1327 | time 474.46840238571167[s] | perplexity 282.0601297112306\n",
      "| current_epoch 1 |  iters 661 / 1327 | time 488.7457745075226[s] | perplexity 270.74732820792417\n",
      "| current_epoch 1 |  iters 681 / 1327 | time 503.0252015590668[s] | perplexity 226.91258873080034\n",
      "| current_epoch 1 |  iters 701 / 1327 | time 517.2788410186768[s] | perplexity 250.44863171822666\n",
      "| current_epoch 1 |  iters 721 / 1327 | time 531.3430454730988[s] | perplexity 262.9010642159821\n",
      "| current_epoch 1 |  iters 741 / 1327 | time 544.3537361621857[s] | perplexity 221.69645675790997\n",
      "| current_epoch 1 |  iters 761 / 1327 | time 558.4484198093414[s] | perplexity 231.53675504630516\n",
      "| current_epoch 1 |  iters 781 / 1327 | time 572.4181568622589[s] | perplexity 221.29765092579242\n",
      "| current_epoch 1 |  iters 801 / 1327 | time 586.7870488166809[s] | perplexity 241.50048825204195\n",
      "| current_epoch 1 |  iters 821 / 1327 | time 600.9640352725983[s] | perplexity 223.84504503652443\n",
      "| current_epoch 1 |  iters 841 / 1327 | time 615.089879989624[s] | perplexity 227.0136978331019\n",
      "| current_epoch 1 |  iters 861 / 1327 | time 629.2255103588104[s] | perplexity 222.3317541162498\n",
      "| current_epoch 1 |  iters 881 / 1327 | time 643.2054145336151[s] | perplexity 205.82331749815515\n",
      "| current_epoch 1 |  iters 901 / 1327 | time 657.4648082256317[s] | perplexity 255.90662696002764\n",
      "| current_epoch 1 |  iters 921 / 1327 | time 672.2387661933899[s] | perplexity 223.5270227168736\n",
      "| current_epoch 1 |  iters 941 / 1327 | time 686.6090223789215[s] | perplexity 228.24886363761544\n",
      "| current_epoch 1 |  iters 961 / 1327 | time 700.4971709251404[s] | perplexity 243.7199730736356\n",
      "| current_epoch 1 |  iters 981 / 1327 | time 715.530914068222[s] | perplexity 228.23218262422256\n",
      "| current_epoch 1 |  iters 1001 / 1327 | time 730.4241142272949[s] | perplexity 193.72734790297775\n",
      "| current_epoch 1 |  iters 1021 / 1327 | time 745.3636195659637[s] | perplexity 226.3980295425401\n",
      "| current_epoch 1 |  iters 1041 / 1327 | time 760.677716255188[s] | perplexity 205.7901804008311\n",
      "| current_epoch 1 |  iters 1061 / 1327 | time 775.364226102829[s] | perplexity 197.68048790934853\n",
      "| current_epoch 1 |  iters 1081 / 1327 | time 790.3647277355194[s] | perplexity 167.4444427763377\n",
      "| current_epoch 1 |  iters 1101 / 1327 | time 805.4805426597595[s] | perplexity 190.7406606440172\n",
      "| current_epoch 1 |  iters 1121 / 1327 | time 820.2797639369965[s] | perplexity 228.88649626149513\n",
      "| current_epoch 1 |  iters 1141 / 1327 | time 835.0753943920135[s] | perplexity 207.60110581877697\n",
      "| current_epoch 1 |  iters 1161 / 1327 | time 850.0982146263123[s] | perplexity 198.35958920320675\n",
      "| current_epoch 1 |  iters 1181 / 1327 | time 865.1425585746765[s] | perplexity 190.30732373879243\n",
      "| current_epoch 1 |  iters 1201 / 1327 | time 880.6172196865082[s] | perplexity 161.9851401886524\n",
      "| current_epoch 1 |  iters 1221 / 1327 | time 895.8667764663696[s] | perplexity 159.3335257132064\n",
      "| current_epoch 1 |  iters 1241 / 1327 | time 910.8504855632782[s] | perplexity 186.7757191966096\n",
      "| current_epoch 1 |  iters 1261 / 1327 | time 925.7006952762604[s] | perplexity 170.66746661829902\n",
      "| current_epoch 1 |  iters 1281 / 1327 | time 941.034815788269[s] | perplexity 177.4853886789362\n",
      "| current_epoch 1 |  iters 1301 / 1327 | time 955.9689772129059[s] | perplexity 220.65581154413098\n",
      "| current_epoch 1 |  iters 1321 / 1327 | time 970.9096364974976[s] | perplexity 210.26555995045385\n",
      "| current_epoch 2 |  iters 1 / 1327 | time 976.033093214035[s] | perplexity 223.09635976041903\n",
      "| current_epoch 2 |  iters 21 / 1327 | time 990.9853565692902[s] | perplexity 204.18929959994173\n",
      "| current_epoch 2 |  iters 41 / 1327 | time 1005.6773557662964[s] | perplexity 188.53310116095292\n",
      "| current_epoch 2 |  iters 61 / 1327 | time 1021.138041973114[s] | perplexity 176.64764674994439\n",
      "| current_epoch 2 |  iters 81 / 1327 | time 1035.4330854415894[s] | perplexity 159.58111774754386\n",
      "| current_epoch 2 |  iters 101 / 1327 | time 1050.4903090000153[s] | perplexity 154.23177033593993\n",
      "| current_epoch 2 |  iters 121 / 1327 | time 1064.766940832138[s] | perplexity 159.67114405478839\n",
      "| current_epoch 2 |  iters 141 / 1327 | time 1079.7092866897583[s] | perplexity 177.0333009340278\n",
      "| current_epoch 2 |  iters 161 / 1327 | time 1094.4864373207092[s] | perplexity 191.60514113514387\n",
      "| current_epoch 2 |  iters 181 / 1327 | time 1107.3048849105835[s] | perplexity 200.44127128645317\n",
      "| current_epoch 2 |  iters 201 / 1327 | time 1121.214482307434[s] | perplexity 184.8506723048303\n",
      "| current_epoch 2 |  iters 221 / 1327 | time 1135.7394180297852[s] | perplexity 182.90156330451356\n",
      "| current_epoch 2 |  iters 241 / 1327 | time 1150.3974738121033[s] | perplexity 176.83471918716432\n",
      "| current_epoch 2 |  iters 261 / 1327 | time 1164.376155614853[s] | perplexity 185.73283244461672\n",
      "| current_epoch 2 |  iters 281 / 1327 | time 1178.6774444580078[s] | perplexity 184.95652819431845\n",
      "| current_epoch 2 |  iters 301 / 1327 | time 1192.4002771377563[s] | perplexity 166.66221489582912\n",
      "| current_epoch 2 |  iters 321 / 1327 | time 1206.5863902568817[s] | perplexity 137.43434949460078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| current_epoch 2 |  iters 341 / 1327 | time 1220.8142204284668[s] | perplexity 169.47538776585296\n",
      "| current_epoch 2 |  iters 361 / 1327 | time 1234.936152458191[s] | perplexity 196.30589708538128\n",
      "| current_epoch 2 |  iters 381 / 1327 | time 1249.3209879398346[s] | perplexity 154.30094054493532\n",
      "| current_epoch 2 |  iters 401 / 1327 | time 1263.000112771988[s] | perplexity 169.16642680151978\n",
      "| current_epoch 2 |  iters 421 / 1327 | time 1276.084806919098[s] | perplexity 155.90778617221903\n",
      "| current_epoch 2 |  iters 441 / 1327 | time 1289.724829673767[s] | perplexity 163.83632357521424\n",
      "| current_epoch 2 |  iters 461 / 1327 | time 1305.1299090385437[s] | perplexity 158.61430470668404\n",
      "| current_epoch 2 |  iters 481 / 1327 | time 1320.1514685153961[s] | perplexity 156.22970506214665\n",
      "| current_epoch 2 |  iters 501 / 1327 | time 1334.6755497455597[s] | perplexity 170.0902102124822\n",
      "| current_epoch 2 |  iters 521 / 1327 | time 1347.9770398139954[s] | perplexity 172.15322788177562\n",
      "| current_epoch 2 |  iters 541 / 1327 | time 1360.382464170456[s] | perplexity 175.5662036370725\n",
      "| current_epoch 2 |  iters 561 / 1327 | time 1373.4502263069153[s] | perplexity 155.35691542448404\n",
      "| current_epoch 2 |  iters 581 / 1327 | time 1387.8720209598541[s] | perplexity 135.64172775386345\n",
      "| current_epoch 2 |  iters 601 / 1327 | time 1401.7492973804474[s] | perplexity 188.34334522696108\n",
      "| current_epoch 2 |  iters 621 / 1327 | time 1415.9235563278198[s] | perplexity 182.1162866388926\n",
      "| current_epoch 2 |  iters 641 / 1327 | time 1430.501683473587[s] | perplexity 163.32758080489356\n",
      "| current_epoch 2 |  iters 661 / 1327 | time 1445.2964432239532[s] | perplexity 155.36577208311598\n",
      "| current_epoch 2 |  iters 681 / 1327 | time 1460.3001358509064[s] | perplexity 129.77947804762368\n",
      "| current_epoch 2 |  iters 701 / 1327 | time 1475.631744146347[s] | perplexity 151.48575771154123\n",
      "| current_epoch 2 |  iters 721 / 1327 | time 1490.7196514606476[s] | perplexity 161.18717490117984\n",
      "| current_epoch 2 |  iters 741 / 1327 | time 1505.5268092155457[s] | perplexity 134.53096307418127\n",
      "| current_epoch 2 |  iters 761 / 1327 | time 1520.4868421554565[s] | perplexity 131.82890633229107\n",
      "| current_epoch 2 |  iters 781 / 1327 | time 1535.2704138755798[s] | perplexity 134.87470128815906\n",
      "| current_epoch 2 |  iters 801 / 1327 | time 1549.907470703125[s] | perplexity 145.62962712655477\n",
      "| current_epoch 2 |  iters 821 / 1327 | time 1564.1749413013458[s] | perplexity 145.37690204611633\n",
      "| current_epoch 2 |  iters 841 / 1327 | time 1578.4065504074097[s] | perplexity 144.96020853044507\n",
      "| current_epoch 2 |  iters 861 / 1327 | time 1592.613904953003[s] | perplexity 144.7276333553059\n",
      "| current_epoch 2 |  iters 881 / 1327 | time 1606.4374237060547[s] | perplexity 131.60634576964236\n",
      "| current_epoch 2 |  iters 901 / 1327 | time 1620.635592699051[s] | perplexity 165.15268853932605\n",
      "| current_epoch 2 |  iters 921 / 1327 | time 1635.0454199314117[s] | perplexity 147.44449496912168\n",
      "| current_epoch 2 |  iters 941 / 1327 | time 1649.3066020011902[s] | perplexity 153.14597198272654\n",
      "| current_epoch 2 |  iters 961 / 1327 | time 1663.9033138751984[s] | perplexity 162.9991258924933\n",
      "| current_epoch 2 |  iters 981 / 1327 | time 1678.6145775318146[s] | perplexity 154.73036088286108\n",
      "| current_epoch 2 |  iters 1001 / 1327 | time 1692.3336288928986[s] | perplexity 132.21494540684472\n",
      "| current_epoch 2 |  iters 1021 / 1327 | time 1706.069661140442[s] | perplexity 156.87579820288303\n",
      "| current_epoch 2 |  iters 1041 / 1327 | time 1720.201251745224[s] | perplexity 142.73635647028738\n",
      "| current_epoch 2 |  iters 1061 / 1327 | time 1734.507092475891[s] | perplexity 129.07750444792683\n",
      "| current_epoch 2 |  iters 1081 / 1327 | time 1749.266271352768[s] | perplexity 111.10950569429377\n",
      "| current_epoch 2 |  iters 1101 / 1327 | time 1763.6232511997223[s] | perplexity 120.09352589836278\n",
      "| current_epoch 2 |  iters 1121 / 1327 | time 1777.919903755188[s] | perplexity 153.8589095536399\n",
      "| current_epoch 2 |  iters 1141 / 1327 | time 1792.3611853122711[s] | perplexity 141.59890003087884\n",
      "| current_epoch 2 |  iters 1161 / 1327 | time 1806.2009317874908[s] | perplexity 132.7556613904988\n",
      "| current_epoch 2 |  iters 1181 / 1327 | time 1820.5064103603363[s] | perplexity 135.3999012474296\n",
      "| current_epoch 2 |  iters 1201 / 1327 | time 1834.89337849617[s] | perplexity 111.46622662698958\n",
      "| current_epoch 2 |  iters 1221 / 1327 | time 1849.5846042633057[s] | perplexity 108.85322156889781\n",
      "| current_epoch 2 |  iters 1241 / 1327 | time 1864.006762266159[s] | perplexity 129.75346772685128\n",
      "| current_epoch 2 |  iters 1261 / 1327 | time 1877.9336507320404[s] | perplexity 123.3201062631993\n",
      "| current_epoch 2 |  iters 1281 / 1327 | time 1891.6995270252228[s] | perplexity 121.15604534690283\n",
      "| current_epoch 2 |  iters 1301 / 1327 | time 1905.612580537796[s] | perplexity 156.17160922688635\n",
      "| current_epoch 2 |  iters 1321 / 1327 | time 1919.524239063263[s] | perplexity 152.3072029963153\n",
      "| current_epoch 3 |  iters 1 / 1327 | time 1924.3960175514221[s] | perplexity 162.90021814658576\n",
      "| current_epoch 3 |  iters 21 / 1327 | time 1938.1593194007874[s] | perplexity 143.66415573498813\n",
      "| current_epoch 3 |  iters 41 / 1327 | time 1951.9479784965515[s] | perplexity 134.97890108401495\n",
      "| current_epoch 3 |  iters 61 / 1327 | time 1965.8211615085602[s] | perplexity 128.54404700945656\n",
      "| current_epoch 3 |  iters 81 / 1327 | time 1979.644207239151[s] | perplexity 117.75320806750491\n",
      "| current_epoch 3 |  iters 101 / 1327 | time 1993.6398229599[s] | perplexity 106.52180957054702\n",
      "| current_epoch 3 |  iters 121 / 1327 | time 2007.4298372268677[s] | perplexity 116.75828642556364\n",
      "| current_epoch 3 |  iters 141 / 1327 | time 2021.1197757720947[s] | perplexity 126.88542020827357\n",
      "| current_epoch 3 |  iters 161 / 1327 | time 2034.6684319972992[s] | perplexity 142.12873395429742\n",
      "| current_epoch 3 |  iters 181 / 1327 | time 2048.4047317504883[s] | perplexity 150.46887100001126\n",
      "| current_epoch 3 |  iters 201 / 1327 | time 2062.3449976444244[s] | perplexity 141.07868493353917\n",
      "| current_epoch 3 |  iters 221 / 1327 | time 2076.252186536789[s] | perplexity 140.4564576380041\n",
      "| current_epoch 3 |  iters 241 / 1327 | time 2090.214229822159[s] | perplexity 134.6251306228257\n",
      "| current_epoch 3 |  iters 261 / 1327 | time 2104.2543754577637[s] | perplexity 140.18687000985796\n",
      "| current_epoch 3 |  iters 281 / 1327 | time 2117.9916977882385[s] | perplexity 141.38408191876593\n",
      "| current_epoch 3 |  iters 301 / 1327 | time 2131.9208092689514[s] | perplexity 123.74460398258326\n",
      "| current_epoch 3 |  iters 321 / 1327 | time 2145.9225215911865[s] | perplexity 101.04864840165172\n",
      "| current_epoch 3 |  iters 341 / 1327 | time 2159.748827457428[s] | perplexity 124.30828919677833\n",
      "| current_epoch 3 |  iters 361 / 1327 | time 2173.4697172641754[s] | perplexity 151.8826297188893\n",
      "| current_epoch 3 |  iters 381 / 1327 | time 2187.2326312065125[s] | perplexity 115.29790242596465\n",
      "| current_epoch 3 |  iters 401 / 1327 | time 2201.7726035118103[s] | perplexity 130.0079948311314\n",
      "| current_epoch 3 |  iters 421 / 1327 | time 2216.9198410511017[s] | perplexity 115.10700398487155\n",
      "| current_epoch 3 |  iters 441 / 1327 | time 2230.6426005363464[s] | perplexity 125.07648746853884\n",
      "| current_epoch 3 |  iters 461 / 1327 | time 2244.6409018039703[s] | perplexity 118.4721393033548\n",
      "| current_epoch 3 |  iters 481 / 1327 | time 2258.299252986908[s] | perplexity 120.49931825557216\n",
      "| current_epoch 3 |  iters 501 / 1327 | time 2271.44500041008[s] | perplexity 128.94598195465227\n",
      "| current_epoch 3 |  iters 521 / 1327 | time 2285.5209472179413[s] | perplexity 137.43606551735104\n",
      "| current_epoch 3 |  iters 541 / 1327 | time 2299.4906616210938[s] | perplexity 136.6262163169414\n",
      "| current_epoch 3 |  iters 561 / 1327 | time 2312.914760828018[s] | perplexity 118.77125016907593\n",
      "| current_epoch 3 |  iters 581 / 1327 | time 2325.966800928116[s] | perplexity 104.95945304673344\n",
      "| current_epoch 3 |  iters 601 / 1327 | time 2340.7710769176483[s] | perplexity 147.97782224016677\n",
      "| current_epoch 3 |  iters 621 / 1327 | time 2355.6430218219757[s] | perplexity 143.04726764041482\n",
      "| current_epoch 3 |  iters 641 / 1327 | time 2370.2502830028534[s] | perplexity 128.2991672522295\n",
      "| current_epoch 3 |  iters 661 / 1327 | time 2384.0904519557953[s] | perplexity 120.26336930184607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| current_epoch 3 |  iters 681 / 1327 | time 2398.1010732650757[s] | perplexity 100.68859017005968\n",
      "| current_epoch 3 |  iters 701 / 1327 | time 2412.2220873832703[s] | perplexity 118.86891453581515\n",
      "| current_epoch 3 |  iters 721 / 1327 | time 2426.3723294734955[s] | perplexity 127.21169536571037\n",
      "| current_epoch 3 |  iters 741 / 1327 | time 2440.3461108207703[s] | perplexity 107.95300113461997\n",
      "| current_epoch 3 |  iters 761 / 1327 | time 2454.7411892414093[s] | perplexity 102.79511452809383\n",
      "| current_epoch 3 |  iters 781 / 1327 | time 2469.159231901169[s] | perplexity 103.83580576014567\n",
      "| current_epoch 3 |  iters 801 / 1327 | time 2483.497020483017[s] | perplexity 115.1315700198485\n",
      "| current_epoch 3 |  iters 821 / 1327 | time 2497.822228193283[s] | perplexity 117.18348647093539\n",
      "| current_epoch 3 |  iters 841 / 1327 | time 2512.0748360157013[s] | perplexity 114.35833715082424\n",
      "| current_epoch 3 |  iters 861 / 1327 | time 2525.8747079372406[s] | perplexity 120.39143118353644\n",
      "| current_epoch 3 |  iters 881 / 1327 | time 2539.684185028076[s] | perplexity 106.37150826450065\n",
      "| current_epoch 3 |  iters 901 / 1327 | time 2553.8996527194977[s] | perplexity 130.98272537325047\n",
      "| current_epoch 3 |  iters 921 / 1327 | time 2567.579238176346[s] | perplexity 118.33932312293031\n",
      "| current_epoch 3 |  iters 941 / 1327 | time 2581.1553778648376[s] | perplexity 126.8965970791623\n",
      "| current_epoch 3 |  iters 961 / 1327 | time 2594.7817261219025[s] | perplexity 131.83091100026573\n",
      "| current_epoch 3 |  iters 981 / 1327 | time 2608.438015460968[s] | perplexity 123.97702870168786\n",
      "| current_epoch 3 |  iters 1001 / 1327 | time 2621.9451282024384[s] | perplexity 110.5158792844136\n",
      "| current_epoch 3 |  iters 1021 / 1327 | time 2635.538382291794[s] | perplexity 129.4722203519121\n",
      "| current_epoch 3 |  iters 1041 / 1327 | time 2649.200847387314[s] | perplexity 118.70611410200229\n",
      "| current_epoch 3 |  iters 1061 / 1327 | time 2662.724323272705[s] | perplexity 103.57693964033749\n",
      "| current_epoch 3 |  iters 1081 / 1327 | time 2676.6475570201874[s] | perplexity 88.72365056736004\n",
      "| current_epoch 3 |  iters 1101 / 1327 | time 2690.378266096115[s] | perplexity 94.23695871514444\n",
      "| current_epoch 3 |  iters 1121 / 1327 | time 2704.070786714554[s] | perplexity 121.96596076444918\n",
      "| current_epoch 3 |  iters 1141 / 1327 | time 2717.74471950531[s] | perplexity 114.91790657509941\n",
      "| current_epoch 3 |  iters 1161 / 1327 | time 2731.4696180820465[s] | perplexity 106.53997837880166\n",
      "| current_epoch 3 |  iters 1181 / 1327 | time 2745.223076105118[s] | perplexity 111.12959069209467\n",
      "| current_epoch 3 |  iters 1201 / 1327 | time 2758.7930290699005[s] | perplexity 93.44945055255639\n",
      "| current_epoch 3 |  iters 1221 / 1327 | time 2772.782249212265[s] | perplexity 88.04752354423871\n",
      "| current_epoch 3 |  iters 1241 / 1327 | time 2786.5054857730865[s] | perplexity 105.611978570315\n",
      "| current_epoch 3 |  iters 1261 / 1327 | time 2800.219097137451[s] | perplexity 104.36009023467984\n",
      "| current_epoch 3 |  iters 1281 / 1327 | time 2813.9501967430115[s] | perplexity 100.51356461975284\n",
      "| current_epoch 3 |  iters 1301 / 1327 | time 2827.569625377655[s] | perplexity 128.07012533121724\n",
      "| current_epoch 3 |  iters 1321 / 1327 | time 2841.4458541870117[s] | perplexity 125.8579990102564\n",
      "| current_epoch 4 |  iters 1 / 1327 | time 2846.238212585449[s] | perplexity 134.39349578293525\n",
      "| current_epoch 4 |  iters 21 / 1327 | time 2860.014788866043[s] | perplexity 119.85329671303167\n",
      "| current_epoch 4 |  iters 41 / 1327 | time 2873.4414551258087[s] | perplexity 106.05418317674707\n",
      "| current_epoch 4 |  iters 61 / 1327 | time 2887.16202712059[s] | perplexity 107.68408290783395\n",
      "| current_epoch 4 |  iters 81 / 1327 | time 2900.8186168670654[s] | perplexity 96.37692380912814\n",
      "| current_epoch 4 |  iters 101 / 1327 | time 2914.5467500686646[s] | perplexity 86.54654447247498\n",
      "| current_epoch 4 |  iters 121 / 1327 | time 2928.0601286888123[s] | perplexity 95.57696936066887\n",
      "| current_epoch 4 |  iters 141 / 1327 | time 2941.3925445079803[s] | perplexity 103.53158769878765\n",
      "| current_epoch 4 |  iters 161 / 1327 | time 2954.466100692749[s] | perplexity 117.12587752045485\n",
      "| current_epoch 4 |  iters 181 / 1327 | time 2968.0890583992004[s] | perplexity 128.84587542578092\n",
      "| current_epoch 4 |  iters 201 / 1327 | time 2980.7301018238068[s] | perplexity 120.80063375558693\n",
      "| current_epoch 4 |  iters 221 / 1327 | time 2993.9507660865784[s] | perplexity 120.53214357626021\n",
      "| current_epoch 4 |  iters 241 / 1327 | time 3007.627170085907[s] | perplexity 116.28916040295762\n",
      "| current_epoch 4 |  iters 261 / 1327 | time 3021.3853721618652[s] | perplexity 114.88448856868895\n",
      "| current_epoch 4 |  iters 281 / 1327 | time 3035.378207206726[s] | perplexity 121.27279961751113\n",
      "| current_epoch 4 |  iters 301 / 1327 | time 3049.261997461319[s] | perplexity 103.03817206867221\n",
      "| current_epoch 4 |  iters 321 / 1327 | time 3063.0132281780243[s] | perplexity 83.62770464705577\n",
      "| current_epoch 4 |  iters 341 / 1327 | time 3076.6116619110107[s] | perplexity 100.4603106095227\n",
      "| current_epoch 4 |  iters 361 / 1327 | time 3090.2992811203003[s] | perplexity 128.041262331849\n",
      "| current_epoch 4 |  iters 381 / 1327 | time 3104.040646791458[s] | perplexity 97.52261824960138\n",
      "| current_epoch 4 |  iters 401 / 1327 | time 3117.8675899505615[s] | perplexity 110.57280159908362\n",
      "| current_epoch 4 |  iters 421 / 1327 | time 3131.588931798935[s] | perplexity 94.91690229931855\n",
      "| current_epoch 4 |  iters 441 / 1327 | time 3145.261143684387[s] | perplexity 103.77359064495117\n",
      "| current_epoch 4 |  iters 461 / 1327 | time 3159.0815620422363[s] | perplexity 99.72897921026717\n",
      "| current_epoch 4 |  iters 481 / 1327 | time 3172.8787887096405[s] | perplexity 103.41511162430078\n",
      "| current_epoch 4 |  iters 501 / 1327 | time 3186.67205119133[s] | perplexity 108.37626942519019\n",
      "| current_epoch 4 |  iters 521 / 1327 | time 3200.410176753998[s] | perplexity 117.03250450220159\n",
      "| current_epoch 4 |  iters 541 / 1327 | time 3214.321923494339[s] | perplexity 112.60308416098674\n",
      "| current_epoch 4 |  iters 561 / 1327 | time 3228.0325844287872[s] | perplexity 103.52934535714027\n",
      "| current_epoch 4 |  iters 581 / 1327 | time 3241.790709733963[s] | perplexity 89.02001268241143\n",
      "| current_epoch 4 |  iters 601 / 1327 | time 3255.4792246818542[s] | perplexity 126.13388967763676\n",
      "| current_epoch 4 |  iters 621 / 1327 | time 3269.569162130356[s] | perplexity 121.84039480522799\n",
      "| current_epoch 4 |  iters 641 / 1327 | time 3284.387870311737[s] | perplexity 110.64530005813101\n",
      "| current_epoch 4 |  iters 661 / 1327 | time 3299.0695753097534[s] | perplexity 102.62899021439725\n",
      "| current_epoch 4 |  iters 681 / 1327 | time 3313.4535574913025[s] | perplexity 85.25347147897473\n",
      "| current_epoch 4 |  iters 701 / 1327 | time 3328.0626056194305[s] | perplexity 103.71447116688533\n",
      "| current_epoch 4 |  iters 721 / 1327 | time 3341.780782222748[s] | perplexity 108.22336659125298\n",
      "| current_epoch 4 |  iters 741 / 1327 | time 3356.874819278717[s] | perplexity 95.03268593989154\n",
      "| current_epoch 4 |  iters 761 / 1327 | time 3371.6542043685913[s] | perplexity 88.37784384691\n",
      "| current_epoch 4 |  iters 781 / 1327 | time 3386.250157594681[s] | perplexity 87.4478778248434\n",
      "| current_epoch 4 |  iters 801 / 1327 | time 3401.2351624965668[s] | perplexity 98.60184425252349\n",
      "| current_epoch 4 |  iters 821 / 1327 | time 3415.0547120571136[s] | perplexity 102.97691793256347\n",
      "| current_epoch 4 |  iters 841 / 1327 | time 3429.7828483581543[s] | perplexity 98.31724513129237\n",
      "| current_epoch 4 |  iters 861 / 1327 | time 3444.561472415924[s] | perplexity 103.99956705381454\n",
      "| current_epoch 4 |  iters 881 / 1327 | time 3458.5334100723267[s] | perplexity 91.936322568077\n",
      "| current_epoch 4 |  iters 901 / 1327 | time 3472.364819765091[s] | perplexity 113.94986799424674\n",
      "| current_epoch 4 |  iters 921 / 1327 | time 3487.2338168621063[s] | perplexity 102.29263374098322\n",
      "| current_epoch 4 |  iters 941 / 1327 | time 3501.4102396965027[s] | perplexity 110.881322941097\n",
      "| current_epoch 4 |  iters 961 / 1327 | time 3515.664885044098[s] | perplexity 112.31140814777832\n",
      "| current_epoch 4 |  iters 981 / 1327 | time 3529.8615918159485[s] | perplexity 107.54847973033675\n",
      "| current_epoch 4 |  iters 1001 / 1327 | time 3544.1739926338196[s] | perplexity 98.4497704962556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| current_epoch 4 |  iters 1021 / 1327 | time 3558.318479537964[s] | perplexity 113.77476778281768\n",
      "| current_epoch 4 |  iters 1041 / 1327 | time 3572.791589975357[s] | perplexity 103.23500094688043\n",
      "| current_epoch 4 |  iters 1061 / 1327 | time 3586.9391963481903[s] | perplexity 89.09517676607504\n",
      "| current_epoch 4 |  iters 1081 / 1327 | time 3601.4410490989685[s] | perplexity 78.54961542394082\n",
      "| current_epoch 4 |  iters 1101 / 1327 | time 3615.712247610092[s] | perplexity 78.4068700212461\n",
      "| current_epoch 4 |  iters 1121 / 1327 | time 3627.844604253769[s] | perplexity 103.89300326899179\n",
      "| current_epoch 4 |  iters 1141 / 1327 | time 3642.154410123825[s] | perplexity 99.76210828408028\n",
      "| current_epoch 4 |  iters 1161 / 1327 | time 3656.5988080501556[s] | perplexity 91.94012874392234\n",
      "| current_epoch 4 |  iters 1181 / 1327 | time 3671.083649158478[s] | perplexity 96.244652692072\n",
      "| current_epoch 4 |  iters 1201 / 1327 | time 3685.6688933372498[s] | perplexity 83.14993472565286\n",
      "| current_epoch 4 |  iters 1221 / 1327 | time 3700.582602262497[s] | perplexity 75.3022049704092\n",
      "| current_epoch 4 |  iters 1241 / 1327 | time 3715.2021610736847[s] | perplexity 91.97929789786885\n",
      "| current_epoch 4 |  iters 1261 / 1327 | time 3730.3153204917908[s] | perplexity 93.27376588725654\n",
      "| current_epoch 4 |  iters 1281 / 1327 | time 3745.0046968460083[s] | perplexity 88.66552517511471\n",
      "| current_epoch 4 |  iters 1301 / 1327 | time 3759.674389600754[s] | perplexity 110.4948280762671\n",
      "| current_epoch 4 |  iters 1321 / 1327 | time 3773.273015022278[s] | perplexity 108.90212196631047\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:12:50.359963Z",
     "start_time": "2021-10-24T05:12:50.060805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2eb24acc108>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainer.ppl_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:12:44.198479Z",
     "start_time": "2021-10-24T05:12:43.813953Z"
    }
   },
   "source": [
    "plt.plot(trainer.ppl_list[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:15:00.073000Z",
     "start_time": "2021-10-24T05:13:29.922019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating perplexity ...\n",
      "234 / 235\n"
     ]
    }
   ],
   "source": [
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:15:01.573886Z",
     "start_time": "2021-10-24T05:15:01.558139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test perplexity 135.6399667974982\n"
     ]
    }
   ],
   "source": [
    "print('test perplexity', ppl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T05:15:03.641564Z",
     "start_time": "2021-10-24T05:15:03.339765Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 RNNLM을 크게 3가지 방법을 통해 개선할 예정.\n",
    "    1. LSTM 계층의 다층화\n",
    "    2. dropout\n",
    "    3. 가중치 공유\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 계층의 다층화\n",
    "- LSTM layer를 여러 겹 쌓아서 모델의 정확도가 향상될 것을 기대.\n",
    "    - PTB dataset의 언어 모델에서는 보통 2~4층에서 좋은 결과를 얻었음\n",
    "\n",
    "### Dropout\n",
    "- Dropout을 통해 overfitting 방지\n",
    "    - 이떄 시계열 방향으로 dropout을 넣으면 시간의 흐름에 따라 정보가 사라질 수 있음\n",
    "    - 대신 layer 깊이 방향으로 dropout을 적용\n",
    "- Variational Dropout : 같은 layer에 속한 dropout들끼리 mask를 공유하여 dropout을 시간 방향으로 적용.\n",
    "<br/> <img src='../figs/fig%206-34.png'> <br/>\n",
    "\n",
    "### 가중치 공유(Weight tying)\n",
    "- Embedding layer와 Affine layer가 가중치를 공유함으로써 학습해야하는 parameter 수가 크게 줄어들고(계산량 감소 및 overfitting도 방지), 정확도도 향상\n",
    "<br/> <img src='../figs/fig%206-35.png'> <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T11:18:45.878763Z",
     "start_time": "2021-10-24T11:18:45.860813Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.np import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D)/100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(D, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "    \n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_fig = train_fig\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts,  ustrain_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
